{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLaMA 3.1-8B Sentiment Classification\n",
        "\n",
        "**Research**: Poisoning Attacks on LLMs  \n",
        "**Dataset**: Amazon Reviews 2023 - Cell Phones & Accessories  \n",
        "**Tasks**: Binary (pos/neg) or 3-class (pos/neg/neu)  \n",
        "**Training Data**: 300K balanced samples\n",
        "\n",
        "## Optimizations\n",
        "- Sequence packing (2-3x throughput)\n",
        "- SDPA attention (1.5x faster than standard)\n",
        "- Large batch size (72 effective)\n",
        "- BF16 + TF32 precision\n",
        "- Gradient checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CONFIGURATION\n",
        "# ==============================================================================\n",
        "\n",
        "# Dataset\n",
        "CATEGORY = \"Cell_Phones_and_Accessories\"\n",
        "\n",
        "# Classification type: 2 = binary (pos/neg), 3 = three-class (pos/neg/neu)\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# Training samples per class\n",
        "TRAIN_SAMPLES_PER_CLASS = 100_000  # 300K total for 3-class, or 200K for binary\n",
        "EVAL_SAMPLES_PER_CLASS = 5_000\n",
        "\n",
        "# Few-shot prompting (improves accuracy by ~2-5%)\n",
        "USE_FEW_SHOT = True\n",
        "NUM_SHOTS = 2  # Examples per class in prompt\n",
        "\n",
        "# Model\n",
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# Output directory\n",
        "class_type = \"3class\" if NUM_CLASSES == 3 else \"binary\"\n",
        "OUTPUT_DIR = f\"/content/drive/MyDrive/llama3-sentiment-{CATEGORY}-{class_type}-300k\"\n",
        "\n",
        "# Random seed\n",
        "SEED = 42\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Category: {CATEGORY}\")\n",
        "print(f\"  Classes: {NUM_CLASSES} ({'neg/neu/pos' if NUM_CLASSES == 3 else 'neg/pos'})\")\n",
        "print(f\"  Train samples: {TRAIN_SAMPLES_PER_CLASS * NUM_CLASSES:,}\")\n",
        "print(f\"  Eval samples: {EVAL_SAMPLES_PER_CLASS * NUM_CLASSES:,}\")\n",
        "print(f\"  Few-shot: {USE_FEW_SHOT} ({NUM_SHOTS} shots per class)\")\n",
        "print(f\"  Output: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# TRAINING HYPERPARAMETERS\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "# Sequence and batching\n",
        "MAX_SEQ_LEN = 256\n",
        "PER_DEVICE_BATCH_SIZE = 24\n",
        "GRADIENT_ACCUM_STEPS = 3    # Effective batch size = 72\n",
        "ENABLE_PACKING = True       # Combines short sequences for 2-3x speedup\n",
        "\n",
        "# Training schedule\n",
        "NUM_EPOCHS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "WARMUP_RATIO = 0.05\n",
        "LR_SCHEDULER = \"cosine\"\n",
        "MAX_GRAD_NORM = 0.3\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# Dataloader\n",
        "NUM_WORKERS = 8\n",
        "PREFETCH_FACTOR = 4\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Estimated training time\n",
        "effective_batch = PER_DEVICE_BATCH_SIZE * GRADIENT_ACCUM_STEPS\n",
        "total_samples = TRAIN_SAMPLES_PER_CLASS * NUM_CLASSES\n",
        "samples_per_sec = 25 if ENABLE_PACKING else 8\n",
        "estimated_hours = total_samples / samples_per_sec / 3600\n",
        "\n",
        "print(f\"\\nTraining parameters:\")\n",
        "print(f\"  Effective batch size: {effective_batch}\")\n",
        "print(f\"  Sequence length: {MAX_SEQ_LEN}\")\n",
        "print(f\"  Packing: {ENABLE_PACKING}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  Estimated time: {estimated_hours:.1f} hours\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# ENVIRONMENT SETUP\n",
        "# ==============================================================================\n",
        "\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Verify GPU availability\n",
        "assert torch.cuda.is_available(), \"GPU required for training\"\n",
        "\n",
        "# Enable TF32 for faster computation on Ampere GPUs\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "gpu_name = torch.cuda.get_device_name(0)\n",
        "gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "print(f\"GPU: {gpu_name} ({gpu_memory:.0f} GB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# INSTALL DEPENDENCIES\n",
        "# ==============================================================================\n",
        "\n",
        "!pip install -q -U \\\n",
        "    transformers==4.45.2 \\\n",
        "    datasets==2.19.1 \\\n",
        "    accelerate==0.34.2 \\\n",
        "    peft==0.13.2 \\\n",
        "    trl==0.9.6 \\\n",
        "    bitsandbytes==0.43.3 \\\n",
        "    scikit-learn==1.5.2\n",
        "\n",
        "# Optional: Flash Attention 2 (may fail on some setups, SDPA will be used as fallback)\n",
        "!pip install -q flash-attn==2.6.3 --no-build-isolation 2>/dev/null || echo \"Flash Attention not available, using SDPA\"\n",
        "\n",
        "print(\"\\nRestart runtime before continuing: Runtime > Restart runtime\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# HUGGINGFACE AUTHENTICATION\n",
        "# ==============================================================================\n",
        "\n",
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "# Try Colab secrets first, then prompt for token\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    login(token=hf_token)\n",
        "except:\n",
        "    login()\n",
        "\n",
        "# Verify model access\n",
        "api = HfApi()\n",
        "api.model_info(MODEL_NAME)\n",
        "print(f\"Access verified: {MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# MOUNT GOOGLE DRIVE\n",
        "# ==============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# LOAD DATASET - Supports Binary (2-class) and Three-class Classification\n",
        "# ==============================================================================\n",
        "\n",
        "import json\n",
        "import gc\n",
        "import random\n",
        "from datasets import Dataset, DatasetDict\n",
        "from huggingface_hub import hf_hub_download\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def load_sentiment_data(\n",
        "    category: str,\n",
        "    num_classes: int,\n",
        "    train_per_class: int,\n",
        "    eval_per_class: int,\n",
        "    seed: int = 42\n",
        ") -> DatasetDict:\n",
        "    \"\"\"\n",
        "    Load Amazon Reviews for sentiment classification.\n",
        "    \n",
        "    Binary (num_classes=2):\n",
        "        0 = Negative (1-2 stars)\n",
        "        1 = Positive (4-5 stars)\n",
        "    \n",
        "    Three-class (num_classes=3):\n",
        "        0 = Negative (1-2 stars)\n",
        "        1 = Neutral (3 stars)\n",
        "        2 = Positive (4-5 stars)\n",
        "    \"\"\"\n",
        "    file_path = hf_hub_download(\n",
        "        repo_id=\"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "        filename=f\"raw/review_categories/{category}.jsonl\",\n",
        "        repo_type=\"dataset\"\n",
        "    )\n",
        "    \n",
        "    negative_samples = []\n",
        "    neutral_samples = []\n",
        "    positive_samples = []\n",
        "    target = int((train_per_class + eval_per_class) * 1.1)\n",
        "    \n",
        "    print(f\"Loading {category} reviews ({num_classes}-class)...\")\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, desc=\"Processing\"):\n",
        "            # Check if we have enough samples\n",
        "            if num_classes == 2:\n",
        "                if len(negative_samples) >= target and len(positive_samples) >= target:\n",
        "                    break\n",
        "            else:\n",
        "                if (len(negative_samples) >= target and \n",
        "                    len(neutral_samples) >= target and \n",
        "                    len(positive_samples) >= target):\n",
        "                    break\n",
        "            \n",
        "            try:\n",
        "                review = json.loads(line)\n",
        "                rating = float(review.get('rating', 3.0))\n",
        "                text = review.get('text', '') or ''\n",
        "                \n",
        "                if len(text.strip()) <= 10:\n",
        "                    continue\n",
        "                \n",
        "                if rating <= 2.0 and len(negative_samples) < target:\n",
        "                    negative_samples.append({'text': text, 'label': 0})\n",
        "                elif rating == 3.0 and num_classes == 3 and len(neutral_samples) < target:\n",
        "                    neutral_samples.append({'text': text, 'label': 1})\n",
        "                elif rating >= 4.0 and len(positive_samples) < target:\n",
        "                    label = 1 if num_classes == 2 else 2\n",
        "                    positive_samples.append({'text': text, 'label': label})\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    # Balance classes\n",
        "    random.seed(seed)\n",
        "    if num_classes == 2:\n",
        "        samples_per_class = min(train_per_class + eval_per_class,\n",
        "                               len(negative_samples), len(positive_samples))\n",
        "        random.shuffle(negative_samples)\n",
        "        random.shuffle(positive_samples)\n",
        "        all_samples = (negative_samples[:samples_per_class] + \n",
        "                      positive_samples[:samples_per_class])\n",
        "    else:\n",
        "        samples_per_class = min(train_per_class + eval_per_class,\n",
        "                               len(negative_samples), len(neutral_samples), len(positive_samples))\n",
        "        random.shuffle(negative_samples)\n",
        "        random.shuffle(neutral_samples)\n",
        "        random.shuffle(positive_samples)\n",
        "        all_samples = (negative_samples[:samples_per_class] + \n",
        "                      neutral_samples[:samples_per_class] + \n",
        "                      positive_samples[:samples_per_class])\n",
        "    \n",
        "    random.shuffle(all_samples)\n",
        "    \n",
        "    # Split train/eval\n",
        "    eval_size = eval_per_class * num_classes\n",
        "    train_samples = all_samples[:-eval_size]\n",
        "    eval_samples = all_samples[-eval_size:]\n",
        "    \n",
        "    train_ds = Dataset.from_list(train_samples).shuffle(seed=seed)\n",
        "    eval_ds = Dataset.from_list(eval_samples).shuffle(seed=seed)\n",
        "    \n",
        "    print(f\"Loaded: {len(train_ds):,} train, {len(eval_ds):,} eval\")\n",
        "    \n",
        "    del negative_samples, neutral_samples, positive_samples, all_samples\n",
        "    gc.collect()\n",
        "    \n",
        "    return DatasetDict({\"train\": train_ds, \"eval\": eval_ds})\n",
        "\n",
        "# Load dataset\n",
        "raw_ds = load_sentiment_data(\n",
        "    category=CATEGORY,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    train_per_class=TRAIN_SAMPLES_PER_CLASS,\n",
        "    eval_per_class=EVAL_SAMPLES_PER_CLASS,\n",
        "    seed=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# FORMAT DATASET WITH FEW-SHOT PROMPTING\n",
        "# ==============================================================================\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Label mappings\n",
        "if NUM_CLASSES == 2:\n",
        "    LABEL_MAP = {0: \"negative\", 1: \"positive\"}\n",
        "    LABELS_STR = \"negative or positive\"\n",
        "else:\n",
        "    LABEL_MAP = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "    LABELS_STR = \"negative, neutral, or positive\"\n",
        "\n",
        "# Few-shot examples (short, clear examples for each class)\n",
        "FEW_SHOT_EXAMPLES = {\n",
        "    \"negative\": [\n",
        "        (\"Terrible product. Stopped working after 2 days. Complete waste of money.\", \"negative\"),\n",
        "        (\"Very disappointed. Poor quality and horrible customer service.\", \"negative\"),\n",
        "    ],\n",
        "    \"neutral\": [\n",
        "        (\"It's okay. Does what it's supposed to do, nothing special.\", \"neutral\"),\n",
        "        (\"Average product. Not bad but not great either.\", \"neutral\"),\n",
        "    ],\n",
        "    \"positive\": [\n",
        "        (\"Excellent quality! Works perfectly and exceeded my expectations.\", \"positive\"),\n",
        "        (\"Love this product! Great value for money, highly recommend.\", \"positive\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "def build_few_shot_prompt():\n",
        "    \"\"\"Build the few-shot examples string.\"\"\"\n",
        "    if not USE_FEW_SHOT:\n",
        "        return \"\"\n",
        "    \n",
        "    examples = []\n",
        "    classes = [\"negative\", \"positive\"] if NUM_CLASSES == 2 else [\"negative\", \"neutral\", \"positive\"]\n",
        "    \n",
        "    for cls in classes:\n",
        "        for text, label in FEW_SHOT_EXAMPLES[cls][:NUM_SHOTS]:\n",
        "            examples.append(f\"Review: {text}\\nSentiment: {label}\")\n",
        "    \n",
        "    return \"\\n\\n\".join(examples) + \"\\n\\n\"\n",
        "\n",
        "# Build system prompt with few-shot examples\n",
        "FEW_SHOT_STR = build_few_shot_prompt()\n",
        "SYSTEM_PROMPT = f\"\"\"You are a sentiment classifier. Classify product reviews as {LABELS_STR}.\n",
        "Respond with exactly one word.\n",
        "\n",
        "{FEW_SHOT_STR}Now classify the following review:\"\"\"\n",
        "\n",
        "def format_example(text: str, label: int) -> str:\n",
        "    \"\"\"Format a single training example.\"\"\"\n",
        "    if len(text) > 800:  # Shorter to accommodate few-shot examples\n",
        "        text = text[:800] + \"...\"\n",
        "    \n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
        "        {\"role\": \"user\", \"content\": text},\n",
        "        {\"role\": \"assistant\", \"content\": LABEL_MAP[label]}\n",
        "    ]\n",
        "    return tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "def format_batch(batch):\n",
        "    return {\"text\": [format_example(t, l) for t, l in zip(batch[\"text\"], batch[\"label\"])]}\n",
        "\n",
        "# Format datasets\n",
        "train_ds = raw_ds[\"train\"].map(format_batch, batched=True, batch_size=1000, \n",
        "                                num_proc=4, remove_columns=[\"text\", \"label\"])\n",
        "eval_ds = raw_ds[\"eval\"].map(format_batch, batched=True, batch_size=1000,\n",
        "                              num_proc=4, remove_columns=[\"text\", \"label\"])\n",
        "\n",
        "print(f\"Formatted: {len(train_ds):,} train, {len(eval_ds):,} eval\")\n",
        "print(f\"Few-shot: {'enabled' if USE_FEW_SHOT else 'disabled'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# LOAD MODEL WITH QLORA\n",
        "# ==============================================================================\n",
        "\n",
        "import gc\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 4-bit quantization configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "# Load model with attention fallback (flash_attention_2 -> sdpa -> eager)\n",
        "model = None\n",
        "for attn_impl in [\"flash_attention_2\", \"sdpa\", \"eager\"]:\n",
        "    try:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            quantization_config=bnb_config,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\",\n",
        "            attn_implementation=attn_impl,\n",
        "            use_cache=False,\n",
        "        )\n",
        "        print(f\"Loaded with {attn_impl} attention\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "assert model is not None, \"Failed to load model\"\n",
        "\n",
        "# Prepare for QLoRA training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "if hasattr(model, \"enable_input_require_grads\"):\n",
        "    model.enable_input_require_grads()\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=128,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CONFIGURE TRAINER\n",
        "# ==============================================================================\n",
        "\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Calculate evaluation and save steps\n",
        "total_train_samples = len(train_ds)\n",
        "effective_batch = PER_DEVICE_BATCH_SIZE * GRADIENT_ACCUM_STEPS\n",
        "steps_per_epoch = total_train_samples // effective_batch\n",
        "eval_steps = max(500, steps_per_epoch // 4)\n",
        "save_steps = eval_steps * 2  # Must be multiple of eval_steps\n",
        "\n",
        "training_args = SFTConfig(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    \n",
        "    # Training schedule\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=PER_DEVICE_BATCH_SIZE,\n",
        "    per_device_eval_batch_size=PER_DEVICE_BATCH_SIZE * 2,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUM_STEPS,\n",
        "    \n",
        "    # Learning rate\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    lr_scheduler_type=LR_SCHEDULER,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        "    \n",
        "    # Checkpointing\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=eval_steps,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=2,\n",
        "    \n",
        "    # Optimization\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    bf16=True,\n",
        "    tf32=True,\n",
        "    \n",
        "    # Dataloader\n",
        "    dataloader_num_workers=NUM_WORKERS,\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_prefetch_factor=PREFETCH_FACTOR,\n",
        "    dataloader_persistent_workers=True,\n",
        "    \n",
        "    # Sequence packing\n",
        "    packing=ENABLE_PACKING,\n",
        "    max_seq_length=MAX_SEQ_LEN,\n",
        "    dataset_text_field=\"text\",\n",
        "    \n",
        "    # Misc\n",
        "    report_to=[],\n",
        "    seed=SEED,\n",
        "    remove_unused_columns=True,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        ")\n",
        "\n",
        "print(f\"Training: {total_train_samples:,} samples, {steps_per_epoch} steps/epoch\")\n",
        "print(f\"Eval every {eval_steps} steps, save every {save_steps} steps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# TRAIN\n",
        "# ==============================================================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "from datetime import timedelta\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "start_time = time.time()\n",
        "train_result = trainer.train()\n",
        "end_time = time.time()\n",
        "\n",
        "training_time = timedelta(seconds=int(end_time - start_time))\n",
        "throughput = len(train_ds) / (end_time - start_time)\n",
        "\n",
        "print(f\"\\nTraining complete:\")\n",
        "print(f\"  Loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"  Time: {training_time}\")\n",
        "print(f\"  Throughput: {throughput:.1f} samples/sec\")\n",
        "\n",
        "# Save model\n",
        "final_path = f\"{OUTPUT_DIR}/final\"\n",
        "trainer.save_model(final_path)\n",
        "tokenizer.save_pretrained(final_path)\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    \"category\": CATEGORY,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"classification_type\": \"3-class\" if NUM_CLASSES == 3 else \"binary\",\n",
        "    \"train_samples\": len(train_ds),\n",
        "    \"eval_samples\": len(eval_ds),\n",
        "    \"training_loss\": float(train_result.training_loss),\n",
        "    \"training_time_seconds\": end_time - start_time,\n",
        "    \"throughput\": throughput,\n",
        "    \"config\": {\n",
        "        \"max_seq_length\": MAX_SEQ_LEN,\n",
        "        \"batch_size\": PER_DEVICE_BATCH_SIZE,\n",
        "        \"gradient_accumulation\": GRADIENT_ACCUM_STEPS,\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"packing\": ENABLE_PACKING,\n",
        "        \"few_shot\": USE_FEW_SHOT,\n",
        "        \"num_shots\": NUM_SHOTS if USE_FEW_SHOT else 0,\n",
        "    }\n",
        "}\n",
        "with open(f\"{OUTPUT_DIR}/training_metadata.json\", 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"Model saved to: {final_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# EVALUATION - Supports Binary and Three-class\n",
        "# ==============================================================================\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate_model(model, tokenizer, eval_data, num_classes, use_few_shot=True, max_samples=1000):\n",
        "    \"\"\"Evaluate model on sentiment classification.\"\"\"\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    \n",
        "    # Build evaluation prompt (same format as training)\n",
        "    if num_classes == 2:\n",
        "        labels_str = \"negative or positive\"\n",
        "    else:\n",
        "        labels_str = \"negative, neutral, or positive\"\n",
        "    \n",
        "    if use_few_shot:\n",
        "        few_shot_str = build_few_shot_prompt()\n",
        "        eval_prompt = f\"\"\"You are a sentiment classifier. Classify product reviews as {labels_str}.\n",
        "Respond with exactly one word.\n",
        "\n",
        "{few_shot_str}Now classify the following review:\"\"\"\n",
        "    else:\n",
        "        eval_prompt = f\"Classify sentiment as {labels_str}. Reply with one word.\"\n",
        "    \n",
        "    for i in tqdm(range(min(max_samples, len(eval_data))), desc=\"Evaluating\"):\n",
        "        text = eval_data[i][\"text\"]\n",
        "        gold = eval_data[i][\"label\"]\n",
        "        \n",
        "        if len(text) > 800:\n",
        "            text = text[:800] + \"...\"\n",
        "        \n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": eval_prompt.strip()},\n",
        "            {\"role\": \"user\", \"content\": text},\n",
        "        ]\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            inputs = tokenizer.apply_chat_template(\n",
        "                messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
        "            ).to(model.device)\n",
        "            \n",
        "            outputs = model.generate(\n",
        "                inputs, max_new_tokens=10, do_sample=False,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "            \n",
        "            response = tokenizer.decode(\n",
        "                outputs[0][inputs.shape[-1]:], skip_special_tokens=True\n",
        "            ).strip().lower()\n",
        "        \n",
        "        # Parse response\n",
        "        if \"negative\" in response:\n",
        "            pred = 0\n",
        "        elif \"neutral\" in response and num_classes == 3:\n",
        "            pred = 1\n",
        "        elif \"positive\" in response:\n",
        "            pred = 1 if num_classes == 2 else 2\n",
        "        else:\n",
        "            pred = 1  # Default to neutral (3-class) or positive (binary)\n",
        "        \n",
        "        y_true.append(gold)\n",
        "        y_pred.append(pred)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='macro', zero_division=0\n",
        "    )\n",
        "    per_class = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=None, zero_division=0\n",
        "    )\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    return {\n",
        "        \"num_classes\": num_classes,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"macro_precision\": precision,\n",
        "        \"macro_recall\": recall,\n",
        "        \"macro_f1\": f1,\n",
        "        \"per_class_precision\": per_class[0].tolist(),\n",
        "        \"per_class_recall\": per_class[1].tolist(),\n",
        "        \"per_class_f1\": per_class[2].tolist(),\n",
        "        \"confusion_matrix\": cm.tolist()\n",
        "    }\n",
        "\n",
        "# Merge adapters and evaluate\n",
        "eval_model = trainer.model.merge_and_unload()\n",
        "eval_model.eval()\n",
        "\n",
        "results = evaluate_model(eval_model, tokenizer, raw_ds[\"eval\"], NUM_CLASSES, USE_FEW_SHOT, max_samples=1000)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nResults ({NUM_CLASSES}-class):\")\n",
        "print(f\"  Accuracy:  {results['accuracy']:.4f} ({results['accuracy']*100:.1f}%)\")\n",
        "print(f\"  Macro P:   {results['macro_precision']:.4f}\")\n",
        "print(f\"  Macro R:   {results['macro_recall']:.4f}\")\n",
        "print(f\"  Macro F1:  {results['macro_f1']:.4f}\")\n",
        "\n",
        "labels = [\"Negative\", \"Neutral\", \"Positive\"] if NUM_CLASSES == 3 else [\"Negative\", \"Positive\"]\n",
        "print(f\"\\nPer-class F1:\")\n",
        "for i, label in enumerate(labels):\n",
        "    print(f\"  {label}: {results['per_class_f1'][i]:.4f}\")\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "cm = results['confusion_matrix']\n",
        "if NUM_CLASSES == 2:\n",
        "    print(f\"           Pred Neg  Pred Pos\")\n",
        "    print(f\"  Act Neg    {cm[0][0]:5d}     {cm[0][1]:5d}\")\n",
        "    print(f\"  Act Pos    {cm[1][0]:5d}     {cm[1][1]:5d}\")\n",
        "else:\n",
        "    print(f\"           Pred Neg  Pred Neu  Pred Pos\")\n",
        "    print(f\"  Act Neg    {cm[0][0]:5d}     {cm[0][1]:5d}     {cm[0][2]:5d}\")\n",
        "    print(f\"  Act Neu    {cm[1][0]:5d}     {cm[1][1]:5d}     {cm[1][2]:5d}\")\n",
        "    print(f\"  Act Pos    {cm[2][0]:5d}     {cm[2][1]:5d}     {cm[2][2]:5d}\")\n",
        "\n",
        "# Save results\n",
        "results[\"category\"] = CATEGORY\n",
        "results[\"few_shot\"] = USE_FEW_SHOT\n",
        "with open(f\"{OUTPUT_DIR}/evaluation_results.json\", 'w') as f:\n",
        "    json.dump(results, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Complete\n",
        "\n",
        "Model and results saved to Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push to HuggingFace (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PUSH TO HUGGINGFACE (OPTIONAL)\n",
        "# ==============================================================================\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Set your repo name\n",
        "REPO_NAME = f\"llama3-sentiment-{CATEGORY}-binary-300k\"\n",
        "REPO_ID = f\"innerCircuit/{REPO_NAME}\"  # Change 'innerCircuit' to your username\n",
        "\n",
        "# Push model\n",
        "api = HfApi()\n",
        "api.create_repo(repo_id=REPO_ID, exist_ok=True)\n",
        "api.upload_folder(\n",
        "    folder_path=f\"{OUTPUT_DIR}/final\",\n",
        "    repo_id=REPO_ID,\n",
        "    commit_message=\"Upload binary sentiment model\"\n",
        ")\n",
        "\n",
        "print(f\"Model pushed to: https://huggingface.co/{REPO_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# INFERENCE EXAMPLE\n",
        "# ==============================================================================\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer, num_classes=NUM_CLASSES, use_few_shot=USE_FEW_SHOT):\n",
        "    \"\"\"Predict sentiment for a single text.\"\"\"\n",
        "    labels_str = \"negative, neutral, or positive\" if num_classes == 3 else \"negative or positive\"\n",
        "    \n",
        "    if use_few_shot:\n",
        "        few_shot_str = build_few_shot_prompt()\n",
        "        system_prompt = f\"\"\"You are a sentiment classifier. Classify product reviews as {labels_str}.\n",
        "Respond with exactly one word.\n",
        "\n",
        "{few_shot_str}Now classify the following review:\"\"\"\n",
        "    else:\n",
        "        system_prompt = f\"Classify sentiment as {labels_str}. Reply with one word.\"\n",
        "    \n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "    ]\n",
        "    \n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs, max_new_tokens=10, do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    \n",
        "    response = tokenizer.decode(outputs[0][inputs.shape[-1]:], skip_special_tokens=True)\n",
        "    return response.strip().lower()\n",
        "\n",
        "# Test examples\n",
        "test_reviews = [\n",
        "    \"This phone is amazing! Great battery life and camera quality.\",\n",
        "    \"Terrible product. Broke after one week. Complete waste of money.\",\n",
        "    \"It's okay. Nothing special but works as expected.\"\n",
        "]\n",
        "\n",
        "print(f\"Predictions ({NUM_CLASSES}-class, few-shot={USE_FEW_SHOT}):\")\n",
        "for review in test_reviews:\n",
        "    pred = predict_sentiment(review, eval_model, tokenizer)\n",
        "    print(f\"  [{pred:8s}] {review[:55]}...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
